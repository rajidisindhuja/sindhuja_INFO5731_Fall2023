{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajidisindhuja/sindhuja_INFO5731_Fall2023/blob/main/Rajidi_Exercise_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wkfVHoCeFba"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 4/18/2023)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71K-NeRseFbc"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training.\n",
        "\n",
        "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data.\n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM\n",
        "\n",
        "(3) KNN\n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "(7) Word2Vec\n",
        "\n",
        "(8) BERT\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison\n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHUcAr52eFbd"
      },
      "outputs": [],
      "source": [
        "# importing all the necessary packages\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qujB7BrzoMJM",
        "outputId": "f330e11a-df9a-4281-ca3e-7c8f8a1871b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training the data set\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read the contents of \"stsa-train.txt\" into a list\n",
        "with open(\"stsa-train.txt\") as txtf:\n",
        "    mylist = [line.rstrip('\\n') for line in txtf]\n",
        "\n",
        "# Initialize lists to store labels and text\n",
        "labels = []\n",
        "text = []\n",
        "\n",
        "# Extract labels and text from each line\n",
        "for i, line in enumerate(mylist):\n",
        "    label = mylist[i][0]\n",
        "    tex = mylist[i][1:]\n",
        "    labels.append(label)\n",
        "    text.append(tex)\n",
        "\n",
        "# Create a DataFrame using the lists of labels and text\n",
        "dataset = pd.DataFrame(list(zip(labels, text)), columns=['Reviews', 'Text'])\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(dataset.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p31_vKJQlw2l",
        "outputId": "d0ac632e-5fb2-4dba-f309-e2012c05fb3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Reviews                                               Text\n",
            "0       1   a stirring , funny and finally transporting r...\n",
            "1       0   apparently reassembled from the cutting-room ...\n",
            "2       0   they presume their audience wo n't sit still ...\n",
            "3       1   this is a visually stunning rumination on lov...\n",
            "4       1   jonathan parker 's bartleby should have been ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing\n",
        "\n",
        "import nltk\n",
        "\n",
        "# Download the 'stopwords' resource\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Import necessary libraries\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "# Download the 'wordnet' resource\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "# Initialize lemmatizer and stemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Define the preprocessing function\n",
        "def preprocess(sentence):\n",
        "    # Convert to lowercase\n",
        "    sentence = str(sentence).lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    sentence = sentence.replace('{html}', '')\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', sentence)\n",
        "\n",
        "    # Remove URLs\n",
        "    rem_url = re.sub(r'http\\S+', '', cleantext)\n",
        "\n",
        "    # Remove numbers\n",
        "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "\n",
        "    # Tokenize and filter out stopwords\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(rem_num)\n",
        "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "\n",
        "    # Stemming\n",
        "    stem_words = [stemmer.stem(w) for w in filtered_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemma_words = [lemmatizer.lemmatize(w) for w in stem_words]\n",
        "\n",
        "    # Join the words back into a sentence\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# we have a DataFrame named 'dataset'\n",
        "# Apply the preprocessing function to a column named 'Text' and create a new column 'cleanText'\n",
        "dataset['cleanText'] = dataset['Text'].map(lambda s: preprocess(s))\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(dataset.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SLEn-d5lxG0",
        "outputId": "12b6dda5-f9e6-4284-912e-cd26c5046b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Reviews                                               Text  \\\n",
            "0       1   a stirring , funny and finally transporting r...   \n",
            "1       0   apparently reassembled from the cutting-room ...   \n",
            "2       0   they presume their audience wo n't sit still ...   \n",
            "3       1   this is a visually stunning rumination on lov...   \n",
            "4       1   jonathan parker 's bartleby should have been ...   \n",
            "\n",
            "                                           cleanText  \n",
            "0  stirring funny finally transporting imagining ...  \n",
            "1  apparently reassembled cutting room floor give...  \n",
            "2  presume audience sit still sociology lesson ho...  \n",
            "3  visually stunning rumination love memory histo...  \n",
            "4  jonathan parker bartleby end modern office ano...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing data set\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read the contents of \"stsa-test.txt\" into a list\n",
        "with open(\"stsa-test.txt\") as txtf:\n",
        "    mylist_test = [line.rstrip('\\n') for line in txtf]\n",
        "\n",
        "# Initialize lists to store labels and text for the test dataset\n",
        "labels_test = []\n",
        "text_test = []\n",
        "\n",
        "# Extract labels and text from each line for the test dataset\n",
        "for i, line in enumerate(mylist_test):\n",
        "    label_test = mylist_test[i][0]\n",
        "    tex_test = mylist_test[i][1:]\n",
        "    labels_test.append(label_test)\n",
        "    text_test.append(tex_test)\n",
        "\n",
        "# Create a DataFrame for the test dataset using the lists of labels and text\n",
        "dataset_test = pd.DataFrame(list(zip(labels_test, text_test)), columns=['Reviews', 'Text'])\n",
        "\n",
        "# Display the first few rows of the test dataset\n",
        "print(dataset_test.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYzTVfr5lxMk",
        "outputId": "02f388f4-9785-42de-e399-49773d2aa560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Reviews                                               Text\n",
            "0       0     no movement , no yuks , not much of anything .\n",
            "1       0   a gob of drivel so sickly sweet , even the ea...\n",
            "2       0   gangs of new york is an unapologetic mess , w...\n",
            "3       0   we never really feel involved with the story ...\n",
            "4       1            this is one of polanski 's best films .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing data preprocessing\n",
        "\n",
        "import nltk\n",
        "nltk.download()\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess(sentence):\n",
        "    sentence=str(sentence)\n",
        "    sentence = sentence.lower()\n",
        "    sentence=sentence.replace('{html}',\"\")\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', sentence)\n",
        "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(rem_num)\n",
        "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "\n",
        "dataset_test['cleanText']=dataset_test['Text'].map(lambda s:preprocess(s))\n",
        "dataset_test.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DEMnynKKlxRC",
        "outputId": "5c089838-e265-4e1e-8eaa-77053238bb8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] bcp47............... BCP-47 Language Tags\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "Hit Enter to continue: \n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "Hit Enter to continue: \n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] punkt............... Punkt Tokenizer Models\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "Hit Enter to continue: \n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "Hit Enter to continue: \n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet2021......... Open English Wordnet 2021\n",
            "  [ ] wordnet2022......... Open English Wordnet 2022\n",
            "  [ ] wordnet31........... Wordnet 3.1\n",
            "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
            "  [ ] words............... Word Lists\n",
            "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
            "                           English Prose\n",
            "\n",
            "Collections:\n",
            "  [P] all-corpora......... All the corpora\n",
            "Hit Enter to continue: \n",
            "  [P] all-nltk............ All packages available on nltk_data gh-pages\n",
            "                           branch\n",
            "  [P] all................. All packages\n",
            "  [P] book................ Everything used in the NLTK Book\n",
            "  [P] popular............. Popular packages\n",
            "  [ ] tests............... Packages for running tests\n",
            "  [ ] third-party......... Third-party data packages\n",
            "\n",
            "([*] marks installed packages; [P] marks partially installed collections)\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> x\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Reviews                                               Text  \\\n",
              "0       0     no movement , no yuks , not much of anything .   \n",
              "1       0   a gob of drivel so sickly sweet , even the ea...   \n",
              "2       0   gangs of new york is an unapologetic mess , w...   \n",
              "3       0   we never really feel involved with the story ...   \n",
              "4       1            this is one of polanski 's best films .   \n",
              "\n",
              "                                           cleanText  \n",
              "0                        movement yuks much anything  \n",
              "1  gob drivel sickly sweet even eager consumers m...  \n",
              "2  gangs new york unapologetic mess whose saving ...  \n",
              "3  never really feel involved story ideas remain ...  \n",
              "4                            one polanski best films  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5e26006-c22b-442d-9ca0-67232bb836aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Text</th>\n",
              "      <th>cleanText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>movement yuks much anything</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>a gob of drivel so sickly sweet , even the ea...</td>\n",
              "      <td>gob drivel sickly sweet even eager consumers m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>gangs of new york is an unapologetic mess , w...</td>\n",
              "      <td>gangs new york unapologetic mess whose saving ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>we never really feel involved with the story ...</td>\n",
              "      <td>never really feel involved story ideas remain ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>one polanski best films</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5e26006-c22b-442d-9ca0-67232bb836aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5e26006-c22b-442d-9ca0-67232bb836aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5e26006-c22b-442d-9ca0-67232bb836aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a2cb40db-019c-49d0-ade3-a7612148ff46\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2cb40db-019c-49d0-ade3-a7612148ff46')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a2cb40db-019c-49d0-ade3-a7612148ff46 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF Vectorization\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase = False, analyzer='word')\n",
        "train_tfidf = tfidf_vectorizer.fit_transform(dataset[\"cleanText\"]).toarray()\n",
        "test_tfidf = tfidf_vectorizer.transform(dataset_test[\"cleanText\"]).toarray()\n"
      ],
      "metadata": {
        "id": "ObhkFh_Hlxaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test_tfidf\n",
        "y_test = dataset_test[\"Reviews\"]\n"
      ],
      "metadata": {
        "id": "OKKtkB7TOOlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for Data partitioning\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train_tfidf,dataset[\"Reviews\"],test_size = 0.2, random_state = 202)"
      ],
      "metadata": {
        "id": "OjhO5OlhOXHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code for MultinominalNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "classifier = MultinomialNB()\n",
        "model = classifier.fit(x_train, y_train)\n",
        "predictions_validation_set = classifier.predict(x_valid)\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "print (\"Accuracy of the Naive Bayes model on validation set is : \", round(accuracy_score(y_valid, predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the Naive Bayes model on validation set is : \", round(precision_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Naive Bayes model on validation set is : \", round(recall_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Naive Bayes model on validation set is : \", round(f1_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K46w7iZHru9t",
        "outputId": "59f9c50e-083e-4e54-8cf9-bf6962593be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Naive Bayes model on validation set is :  78 %\n",
            "Percision of the Naive Bayes model on validation set is :  83 %\n",
            "Recall of the Naive Bayes model on validation set is :  69 %\n",
            "F1 Score of the Naive Bayes model on validation set is :  76 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_naive_validation = classification_report(y_valid, predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_naive_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VCK-t8grvDt",
        "outputId": "6ad73d0f-c423-42db-df90-ad56e6f7de24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:  \n",
            " \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.69      0.76       667\n",
            "           1       0.75      0.87      0.81       717\n",
            "\n",
            "    accuracy                           0.78      1384\n",
            "   macro avg       0.79      0.78      0.78      1384\n",
            "weighted avg       0.79      0.78      0.78      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "naive_accuracies_validation = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"Naive Bayes Model  10-fold cross validation score on training set is :  {round(naive_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8zhiXb-Os8p",
        "outputId": "caf48d74-cacf-47d7-abbe-1f3e5525b894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Model  10-fold cross validation score on training set is :  77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test_set = classifier.predict(x_test)\n",
        "print (\"Accuracy of the Naive Bayes model on test set is : \", round(accuracy_score(y_test, predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the Naive Bayes model on validation set is : \", round(precision_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Naive Bayes model on validation set is : \", round(recall_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Naive Bayes model on validation set is : \", round(f1_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pnw8pHT1OtCJ",
        "outputId": "e3bfbb80-6862-4469-ae8e-21f3ddbc00a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Naive Bayes model on test set is :  79 %\n",
            "Percision of the Naive Bayes model on validation set is :  86 %\n",
            "Recall of the Naive Bayes model on validation set is :  71 %\n",
            "F1 Score of the Naive Bayes model on validation set is :  78 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cr_naive_test = classification_report(y_test, predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_naive_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H97DaDbYO91h",
        "outputId": "e8ee26b0-45b8-45d6-9b6e-704917cc3273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:  \n",
            " \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78       912\n",
            "           1       0.75      0.88      0.81       909\n",
            "\n",
            "    accuracy                           0.79      1821\n",
            "   macro avg       0.80      0.79      0.79      1821\n",
            "weighted avg       0.80      0.79      0.79      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_accuracies_test = cross_val_score(estimator = classifier, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"Naive Bayes Model 10-fold cross validation score on testing set is :  {round(naive_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytk9uc-7O96_",
        "outputId": "d2aa6d95-d689-44ad-969c-74e55eda38cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Model 10-fold cross validation score on testing set is :  73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YXYA7Oq4O-Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# support vector machine SVM\n",
        "from sklearn import svm\n",
        "\n",
        "classifier_svm = svm.SVC()\n",
        "model_svm = classifier_svm.fit(x_train, y_train)\n",
        "svm_predictions_validation_set = classifier_svm.predict(x_valid)\n",
        "\n",
        "print (\"Accuracy of the SVM model on validation set is : \", round(accuracy_score(y_valid, svm_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the SVM model on validation set is : \", round(precision_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the SVM model on validation set is : \", round(recall_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the SVM model on validation set is : \", round(f1_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ma7BcH3PCz8",
        "outputId": "d352173c-a6ff-49b0-8143-a1652a0d0237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the SVM model on validation set is :  79 %\n",
            "Percision of the SVM model on validation set is :  79 %\n",
            "Recall of the SVM model on validation set is :  76 %\n",
            "F1 Score of the SVM model on validation set is :  77 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_svm_validation = classification_report(y_valid, svm_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_svm_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0oVhaUIPC8U",
        "outputId": "80f2952f-a693-4c24-99d3-a781be4f7129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:  \n",
            " \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.76      0.77       667\n",
            "           1       0.78      0.82      0.80       717\n",
            "\n",
            "    accuracy                           0.79      1384\n",
            "   macro avg       0.79      0.79      0.79      1384\n",
            "weighted avg       0.79      0.79      0.79      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "svm_accuracies_validation = cross_val_score(estimator = classifier_svm, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"SVM Model  10-fold cross validation score on training set is :  {round(svm_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruPZfo-wPWJr",
        "outputId": "d0175bf3-4621-4fde-acab-4c361c3c7baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Model  10-fold cross validation score on training set is :  77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_predictions_test_set = classifier_svm.predict(x_test)\n",
        "print (\"Accuracy of the SVM model on test set is : \", round(accuracy_score(y_test, svm_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the SVM model on validation set is : \", round(precision_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the SVM model on validation set is : \", round(recall_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the SVM model on validation set is : \", round(f1_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "4ZZ7YxeqPWNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706e4ddf-8d06-4b8d-cf11-46b58bb7c976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the SVM model on test set is :  79 %\n",
            "Percision of the SVM model on validation set is :  82 %\n",
            "Recall of the SVM model on validation set is :  75 %\n",
            "F1 Score of the SVM model on validation set is :  78 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cr_svm_test = classification_report(y_test, svm_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_svm_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzySynv3PWQl",
        "outputId": "7d3ad971-a99b-4dc5-be5f-d7212cfc3b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:  \n",
            " \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.75      0.78       912\n",
            "           1       0.77      0.84      0.80       909\n",
            "\n",
            "    accuracy                           0.79      1821\n",
            "   macro avg       0.80      0.79      0.79      1821\n",
            "weighted avg       0.80      0.79      0.79      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_accuracies_test = cross_val_score(estimator = classifier_svm, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"SVM Model 10-fold cross validation score on testing set is :  {round(svm_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "LLjtUaGvPWUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21bf52f-3a9d-46b5-bdb1-1919d58bbf33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Model 10-fold cross validation score on testing set is :  72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k nearest neighbour KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "classifier_knn = KNeighborsClassifier(n_neighbors = 15)\n",
        "model_knn = classifier_knn.fit(x_train, y_train)\n",
        "knn_predictions_validation_set = classifier_knn.predict(x_valid)\n",
        "\n",
        "print (\"Accuracy of the KNN model on validation set is : \", round(accuracy_score(y_valid, knn_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the KNN model on validation set is : \", round(precision_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the KNN model on validation set is : \", round(recall_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the KNN model on validation set is : \", round(f1_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scp-_pV5PWYj",
        "outputId": "e6707f80-5410-4be0-de36-66abca69657d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the KNN model on validation set is :  74 %\n",
            "Percision of the KNN model on validation set is :  71 %\n",
            "Recall of the KNN model on validation set is :  78 %\n",
            "F1 Score of the KNN model on validation set is :  74 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_knn_validation = classification_report(y_valid, knn_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_knn_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqOD9Vo6QJgv",
        "outputId": "cddcabf1-13ed-496b-f7b1-65ef24528547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:  \n",
            " \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.78      0.74       667\n",
            "           1       0.77      0.71      0.74       717\n",
            "\n",
            "    accuracy                           0.74      1384\n",
            "   macro avg       0.74      0.74      0.74      1384\n",
            "weighted avg       0.74      0.74      0.74      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "knn_accuracies_validation = cross_val_score(estimator = classifier_knn, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"KNN Model  10-fold cross validation score on training set is :  {round(knn_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XE3uyA2QJki",
        "outputId": "20105c59-1c9f-4d0f-9156-449f8644c46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Model  10-fold cross validation score on training set is :  70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_predictions_test_set = classifier_knn.predict(x_test)\n",
        "print (\"Accuracy of the KNN model on test set is : \", round(accuracy_score(y_test, knn_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the KNN model on validation set is : \", round(precision_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the KNN model on validation set is : \", round(recall_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the KNN model on validation set is : \", round(f1_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUCotoUmQJoL",
        "outputId": "5e50f25a-1a23-4ca3-9c09-a9e8bfe8e3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the KNN model on test set is :  73 %\n",
            "Percision of the KNN model on validation set is :  71 %\n",
            "Recall of the KNN model on validation set is :  77 %\n",
            "F1 Score of the KNN model on validation set is :  74 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cr_knn_test = classification_report(y_test, knn_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_knn_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6an1zDirQJrk",
        "outputId": "dc008e5b-9430-4530-bef8-dbb5c6d4c7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:  \n",
            " \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.77      0.74       912\n",
            "           1       0.75      0.69      0.72       909\n",
            "\n",
            "    accuracy                           0.73      1821\n",
            "   macro avg       0.73      0.73      0.73      1821\n",
            "weighted avg       0.73      0.73      0.73      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_accuracies_test = cross_val_score(estimator = classifier_knn, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"KNN Model 10-fold cross validation score on testing set is :  {round(knn_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0vf1O5HQJu6",
        "outputId": "fce4d7e7-c65a-47e0-921b-efd2c87d0401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Model 10-fold cross validation score on testing set is :  63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rWBHl37GQfYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decison Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "classifier_dt = DecisionTreeClassifier()\n",
        "model_dt = classifier_dt.fit(x_train, y_train)\n",
        "dt_predictions_validation_set = classifier_dt.predict(x_valid)\n",
        "\n",
        "print (\"Accuracy of the Decison Tree Classifier model on validation set is : \", round(accuracy_score(y_valid, dt_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the Decison Tree Classifier model on validation set is : \", round(precision_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Decison Tree Classifier model on validation set is : \", round(recall_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Decison Tree Classifier model on validation set is : \", round(f1_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5R8p_M9QfdA",
        "outputId": "d78f1aa4-2132-415b-adbe-17389e8fb7a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Decison Tree Classifier model on validation set is :  65 %\n",
            "Percision of the Decison Tree Classifier model on validation set is :  62 %\n",
            "Recall of the Decison Tree Classifier model on validation set is :  70 %\n",
            "F1 Score of the Decison Tree Classifier model on validation set is :  66 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_dt_validation = classification_report(y_valid, dt_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_dt_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICyf8GusQJyh",
        "outputId": "2a58ef90-685d-4fbe-d9d5-e349cbb629a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:  \n",
            " \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.70      0.66       667\n",
            "           1       0.68      0.59      0.63       717\n",
            "\n",
            "    accuracy                           0.65      1384\n",
            "   macro avg       0.65      0.65      0.64      1384\n",
            "weighted avg       0.65      0.65      0.64      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "dt_accuracies_validation = cross_val_score(estimator = classifier_dt, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"Decison Tree Classifier Model  10-fold cross validation score on training set is :  {round(dt_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C01g1e2DQ9aj",
        "outputId": "dd347190-97c6-4421-aae7-a05702e66c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decison Tree Classifier Model  10-fold cross validation score on training set is :  65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_predictions_test_set = classifier_dt.predict(x_test)\n",
        "print (\"validation set : Accuracy of the Decison Tree Classifier model on test set is : \", round(accuracy_score(y_test, dt_predictions_test_set)*100),\"%\")\n",
        "print (\"validation set : Percision of the Decison Tree Classifier model  is : \", round(precision_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"validation set : Recall of the Decison Tree Classifier model  is : \", round(recall_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"validation set : F1 Score of the Decison Tree Classifier model is : \", round(f1_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n-sPpzfQ9g8",
        "outputId": "34e1b5ee-b7b2-4445-da36-b4f61544886c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation set : Accuracy of the Decison Tree Classifier model on test set is :  66 %\n",
            "validation set : Percision of the Decison Tree Classifier model  is :  65 %\n",
            "validation set : Recall of the Decison Tree Classifier model  is :  69 %\n",
            "validation set : F1 Score of the Decison Tree Classifier model is :  67 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cr_dt_test = classification_report(y_test, dt_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_dt_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW2F4snZQ9kc",
        "outputId": "eb4dacaa-1ce3-4c32-82c8-a696e2bc19d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:  \n",
            " \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.69      0.67       912\n",
            "           1       0.67      0.63      0.65       909\n",
            "\n",
            "    accuracy                           0.66      1821\n",
            "   macro avg       0.66      0.66      0.66      1821\n",
            "weighted avg       0.66      0.66      0.66      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_accuracies_test = cross_val_score(estimator = classifier_dt, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"Decison Tree Classifier Model 10-fold cross validation score on testing set is :  {round(dt_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxToeJ8jQ9oD",
        "outputId": "29c000bf-665e-4d3e-a310-a8e6f3d5f071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decison Tree Classifier Model 10-fold cross validation score on testing set is :  62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WHZ1ba2GRKi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Randomforest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classifier_rf = RandomForestClassifier()\n",
        "model_rf = classifier_rf.fit(x_train, y_train)\n",
        "rf_predictions_validation_set = classifier_rf.predict(x_valid)\n",
        "\n",
        "print (\"validation set : Accuracy of the Random Forest Classifier model is : \", round(accuracy_score(y_valid, rf_predictions_validation_set)*100),\"%\")\n",
        "print (\"validation set : Percision of the Random Forest Classifier model  is : \", round(precision_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"validation set : Recall of the Random Forest Classifier model  is : \", round(recall_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"validation set : F1 Score of the Random Forest Classifier model  is : \", round(f1_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcfAqdBWRKuR",
        "outputId": "3f588d9f-666a-490f-8168-49e21b19380a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation set : Accuracy of the Random Forest Classifier model is :  73 %\n",
            "validation set : Percision of the Random Forest Classifier model  is :  71 %\n",
            "validation set : Recall of the Random Forest Classifier model  is :  72 %\n",
            "validation set : F1 Score of the Random Forest Classifier model  is :  72 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_rf_validation = classification_report(y_valid, rf_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_rf_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cQbhCuKQ9sB",
        "outputId": "2a7aca93-14dd-49db-823d-5f085e092b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:  \n",
            " \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.72      0.72       667\n",
            "           1       0.74      0.73      0.73       717\n",
            "\n",
            "    accuracy                           0.73      1384\n",
            "   macro avg       0.73      0.73      0.73      1384\n",
            "weighted avg       0.73      0.73      0.73      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "rf_accuracies_validation = cross_val_score(estimator = classifier_rf, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"Decison Random Forest Model  10-fold cross validation score on training set is :  {round(rf_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIYbGjVQRROf",
        "outputId": "3c5d3b09-d4b9-40b3-8d5b-0a0da277047d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decison Random Forest Model  10-fold cross validation score on training set is :  73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_predictions_test_set = classifier_rf.predict(x_test)\n",
        "print (\"Test set : Accuracy of the Random Forest Classifier model  : \", round(accuracy_score(y_test, rf_predictions_test_set)*100),\"%\")\n",
        "print (\"validation set : Percision of the Random Forest Classifier model  is : \", round(precision_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"validation set : Recall of the Random Forest Classifier model  is : \", round(recall_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"validation set : F1 Score of the Random Forest Classifier model  is : \", round(f1_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbsQQqWfRRZn",
        "outputId": "b8a39c5e-8fee-44fe-9d6e-93a02cbdccfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set : Accuracy of the Random Forest Classifier model  :  74 %\n",
            "validation set : Percision of the Random Forest Classifier model  is :  73 %\n",
            "validation set : Recall of the Random Forest Classifier model  is :  76 %\n",
            "validation set : F1 Score of the Random Forest Classifier model  is :  74 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cr_rf_test = classification_report(y_test, rf_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_rf_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q15iC5m6RRhw",
        "outputId": "6324d28b-ede0-4c45-b45c-3b15fdc7a00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:  \n",
            " \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.76      0.74       912\n",
            "           1       0.75      0.72      0.74       909\n",
            "\n",
            "    accuracy                           0.74      1821\n",
            "   macro avg       0.74      0.74      0.74      1821\n",
            "weighted avg       0.74      0.74      0.74      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_accuracies_test = cross_val_score(estimator = classifier_rf, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"Random Forest Classifier Model 10-fold cross validation score on testing set is :  {round(rf_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjQkutcKRcip",
        "outputId": "8b770682-8745-477f-9980-560a0b49c4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Model 10-fold cross validation score on testing set is :  65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HqkVc7tFRcmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert '0' and '1' to 0 and 1 in the target variable\n",
        "y_train_numeric = y_train.astype(int)\n",
        "y_valid_numeric = y_valid.astype(int)\n",
        "\n",
        "classifier_xgb = XGBClassifier()\n",
        "model_xgb = classifier_xgb.fit(x_train, y_train_numeric)\n",
        "xgb_predictions_validation_set = classifier_xgb.predict(x_valid)\n",
        "\n",
        "print(\"Validation set: Accuracy of the XGBoost Classifier model is:\", round(accuracy_score(y_valid_numeric, xgb_predictions_validation_set) * 100), \"%\")\n",
        "print(\"Validation set: Precision of the XGBoost Classifier model is:\", round(precision_score(y_valid_numeric, xgb_predictions_validation_set) * 100), \"%\")\n",
        "print(\"Validation set: Recall of the XGBoost Classifier model is:\", round(recall_score(y_valid_numeric, xgb_predictions_validation_set) * 100), \"%\")\n",
        "print(\"Validation set: F1 Score of the XGBoost Classifier model is:\", round(f1_score(y_valid_numeric, xgb_predictions_validation_set) * 100), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91DxG6USRjcG",
        "outputId": "5dee1965-a310-414c-e75a-b1c7ea3c7651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set: Accuracy of the XGBoost Classifier model is: 68 %\n",
            "Validation set: Precision of the XGBoost Classifier model is: 66 %\n",
            "Validation set: Recall of the XGBoost Classifier model is: 80 %\n",
            "Validation set: F1 Score of the XGBoost Classifier model is: 72 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert '0' and '1' to 0 and 1 in the target variable for y_true\n",
        "y_valid_numeric = y_valid.astype(int)\n",
        "\n",
        "# Assuming you already have the XGBoost classifier and predictions\n",
        "xgb_predictions_validation_set = classifier_xgb.predict(x_valid)\n",
        "\n",
        "# Convert '0' and '1' to 0 and 1 in the predicted values for y_pred\n",
        "xgb_predictions_numeric = xgb_predictions_validation_set.astype(int)\n",
        "\n",
        "# Convert y_valid to numeric format for accurate comparison\n",
        "y_valid_numeric = y_valid.astype(int)\n",
        "\n",
        "cr_xgb_validation = classification_report(y_valid_numeric, xgb_predictions_numeric)\n",
        "print(\"Classification Report:\\n\", cr_xgb_validation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qo9W1ffRjh0",
        "outputId": "e6e234aa-db05-4c31-f523-f392e6994d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.56      0.63       667\n",
            "           1       0.66      0.80      0.72       717\n",
            "\n",
            "    accuracy                           0.68      1384\n",
            "   macro avg       0.69      0.68      0.68      1384\n",
            "weighted avg       0.69      0.68      0.68      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Convert '0' and '1' to 0 and 1 in the target variable for y_train\n",
        "y_train_numeric = y_train.astype(int)\n",
        "\n",
        "# Assuming you already have the XGBoost classifier\n",
        "classifier_xgb = XGBClassifier()\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "xgb_accuracies_validation = cross_val_score(estimator=classifier_xgb, X=x_train, y=y_train_numeric, cv=10)\n",
        "\n",
        "print(f\"XGBoost Model 10-fold cross-validation score on training set is: {round(np.mean(xgb_accuracies_validation) * 100)}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRA413lTRsYc",
        "outputId": "88a41805-f0c0-457f-9db9-6beaf1bd5aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model 10-fold cross-validation score on training set is: 70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert '0' and '1' to 0 and 1 in the target variable for y_train\n",
        "y_train_numeric = y_train.astype(int)\n",
        "\n",
        "# Assuming you already have the XGBoost classifier\n",
        "classifier_xgb = XGBClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "model_xgb = classifier_xgb.fit(x_train, y_train_numeric)\n",
        "\n",
        "# Now you can make predictions on the test set\n",
        "xgb_predictions_test_set = classifier_xgb.predict(x_test)\n",
        "\n",
        "# Convert '0' and '1' to 0 and 1 in the target variable for y_test\n",
        "y_test_numeric = y_test.astype(int)\n",
        "\n",
        "print(\"Test set: Accuracy of the XGBoost Classifier model is:\", round(accuracy_score(y_test_numeric, xgb_predictions_test_set) * 100), \"%\")\n",
        "print(\"Test set: Precision of the XGBoost Classifier model is:\", round(precision_score(y_test_numeric, xgb_predictions_test_set, pos_label=1) * 100), \"%\")\n",
        "print(\"Test set: Recall of the XGBoost Classifier model is:\", round(recall_score(y_test_numeric, xgb_predictions_test_set, pos_label=1) * 100), \"%\")\n",
        "print(\"Test set: F1 Score of the XGBoost Classifier model is:\", round(f1_score(y_test_numeric, xgb_predictions_test_set, pos_label=1) * 100), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fup6nb8FRscS",
        "outputId": "cd448b6a-40fc-4c6d-d326-13810fc7cd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Accuracy of the XGBoost Classifier model is: 69 %\n",
            "Test set: Precision of the XGBoost Classifier model is: 66 %\n",
            "Test set: Recall of the XGBoost Classifier model is: 79 %\n",
            "Test set: F1 Score of the XGBoost Classifier model is: 72 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert '0' and '1' to 0 and 1 in the target variable for y_train\n",
        "y_train_numeric = y_train.astype(int)\n",
        "\n",
        "# Assuming you already have the XGBoost classifier\n",
        "classifier_xgb = XGBClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "model_xgb = classifier_xgb.fit(x_train, y_train_numeric)\n",
        "\n",
        "# Now you can make predictions on the test set\n",
        "xgb_predictions_test_set = classifier_xgb.predict(x_test)\n",
        "\n",
        "# Convert '0' and '1' to 0 and 1 in the target variable for y_test\n",
        "y_test_numeric = y_test.astype(int)\n",
        "\n",
        "# Generate the classification report\n",
        "cr_xgb_test = classification_report(y_test_numeric, xgb_predictions_test_set)\n",
        "print(\"Classification Report:\\n\", cr_xgb_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om-CGIy3RsgL",
        "outputId": "7634542d-5dcc-43f9-aa6f-d88177f13fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.60      0.66       912\n",
            "           1       0.66      0.79      0.72       909\n",
            "\n",
            "    accuracy                           0.69      1821\n",
            "   macro avg       0.70      0.69      0.69      1821\n",
            "weighted avg       0.70      0.69      0.69      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Convert '0' and '1' to 0 and 1 in the target variable for y_train\n",
        "y_train_numeric = y_train.astype(int)\n",
        "\n",
        "# Assuming you already have the XGBoost classifier\n",
        "classifier_xgb = XGBClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "model_xgb = classifier_xgb.fit(x_train, y_train_numeric)\n",
        "\n",
        "# Now you can make predictions on the test set\n",
        "xgb_predictions_test_set = classifier_xgb.predict(x_test)\n",
        "\n",
        "# Convert '0' and '1' to 0 and 1 in the target variable for y_test\n",
        "y_test_numeric = y_test.astype(int)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "accuracy_test = accuracy_score(y_test_numeric, xgb_predictions_test_set)\n",
        "\n",
        "print(f\"Accuracy of XGBoost Classifier Model on the test set: {round(accuracy_test * 100)}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdA61cYLRsk3",
        "outputId": "2802b1e4-c072-4029-c029-1b01c2708daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of XGBoost Classifier Model on the test set: 69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kSHRkQW9Rsp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nuR-v1XnR8tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzUDqKlZR8xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10m37KkDeFbe"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K-means\n",
        "\n",
        "DBSCAN\n",
        "\n",
        "Hierarchical clustering\n",
        "\n",
        "Word2Vec\n",
        "\n",
        "BERT\n",
        "\n",
        "You can refer to of the codes from  the follwing link below.\n",
        "https://www.kaggle.com/karthik3890/text-clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BpR05VcneFbf",
        "outputId": "8a14a6b5-9016-4e6d-8402-74f20e5c36d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Product Name Brand Name   Price  \\\n",
              "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
              "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
              "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
              "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
              "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
              "\n",
              "   Rating                                            Reviews  Review Votes  \n",
              "0       5  feel lucky found used phone used hard phone li...           1.0  \n",
              "1       4  nice phone nice grade pantach revue clean set ...           0.0  \n",
              "2       5                                            pleased           0.0  \n",
              "3       4     works good goes slow sometimes good phone love           0.0  \n",
              "4       4  great phone replace lost phone thing volume bu...           0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e54ea1bd-cf8f-42a5-9a36-1b4c7148f3fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>feel lucky found used phone used hard phone li...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone nice grade pantach revue clean set ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>pleased</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>works good goes slow sometimes good phone love</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>great phone replace lost phone thing volume bu...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e54ea1bd-cf8f-42a5-9a36-1b4c7148f3fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e54ea1bd-cf8f-42a5-9a36-1b4c7148f3fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e54ea1bd-cf8f-42a5-9a36-1b4c7148f3fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d7c39fb-2a59-481f-9c34-e50b27108062\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d7c39fb-2a59-481f-9c34-e50b27108062')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d7c39fb-2a59-481f-9c34-e50b27108062 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "#Write your code here.\n",
        "#K MEANS\n",
        "df = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
        "\n",
        "df['Reviews']=df['Reviews'].map(lambda s:preprocess(s))\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF VECTORIZATION\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
        "\n",
        "# Assuming you have a DataFrame named df with a 'Reviews' column\n",
        "#df = pd.read_csv('Amazon_Unlocked_Mobile.csv')  # Replace '.csv' with the actual file path or URL\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vects = tfidf_vect.fit_transform(df['Reviews'].values.astype('U'))\n",
        "names = tfidf_vect.get_feature_names()"
      ],
      "metadata": {
        "id": "nzk_q8rpkSx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ELBOW METHOD\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(2,12):\n",
        "    kmeans = KMeans(n_clusters = i, init = \"k-means++\", random_state = 101)\n",
        "    kmeans.fit(tfidf_vects)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize = (11,6))\n",
        "plt.plot(range(2,12), wcss, marker = \"o\")\n",
        "plt.title (\"The Elbow Method\")\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.ylabel(\"WCSS\")"
      ],
      "metadata": {
        "id": "m65eqHotkWQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forming 6 clusters\n",
        "from sklearn.cluster import KMeans\n",
        "model = KMeans(n_clusters = 6,init='k-means++',max_iter=10000, random_state=50)\n",
        "model.fit(tfidf_vects)\n",
        "from collections import Counter\n",
        "Counter(model.labels_)"
      ],
      "metadata": {
        "id": "NGog8v2BVl-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clusters containing words with maximum strength\n",
        "top_words = 7\n",
        "centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "for cluster_num in range(6):\n",
        "    key_features = [names[i] for i in centroids[cluster_num, :top_words]]\n",
        "    print('Cluster '+str(cluster_num+1))\n",
        "    print('Top Words:', key_features)"
      ],
      "metadata": {
        "id": "EX-gSCOGVmDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_center=model.cluster_centers_\n",
        "cluster_center"
      ],
      "metadata": {
        "id": "_ZiuJ21JVmIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DBSCAN\n",
        "\n",
        "reviews=[]\n",
        "for i in df['Reviews']:\n",
        "    reviews.append(str(i).split())\n",
        "import gensim\n",
        "w2v_model = gensim.models.Word2Vec(reviews, vector_size=100, workers=4)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "vectors = []\n",
        "for i in reviews:\n",
        "    vector = np.zeros(100)\n",
        "    count = 0\n",
        "    for word in i:\n",
        "        try:\n",
        "            vec = w2v_model.wv[word]\n",
        "            vector += vec\n",
        "            count += 1\n",
        "        except:\n",
        "            pass\n",
        "    vector /= count\n",
        "    vectors.append(vector)\n",
        "vectors = np.array(vectors)\n",
        "vectors = np.nan_to_num(vectors)\n"
      ],
      "metadata": {
        "id": "ZEqLqYzwkcUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "minPts = 2 * 100\n",
        "# Lower bound function\n",
        "def lower_bound(nums, target):\n",
        "    l, r = 0, len(nums) - 1\n",
        "    # Binary searching\n",
        "    while l <= r:\n",
        "        mid = int(l + (r - l) / 2)\n",
        "        if nums[mid] >= target:\n",
        "            r = mid - 1\n",
        "        else:\n",
        "            l = mid + 1\n",
        "    return l\n",
        "\n",
        "def compute200thnearestneighbour(x, data):\n",
        "    dists = []\n",
        "    for val in data:\n",
        "      # computing distances\n",
        "        dist = np.sum((x - val) **2 )\n",
        "        if(len(dists) == 200 and dists[199] > dist):\n",
        "            l = int(lower_bound(dists, dist))\n",
        "            if l < 200 and l >= 0 and dists[l] > dist:\n",
        "                dists[l] = dist\n",
        "        else:\n",
        "            dists.append(dist)\n",
        "            dists.sort()\n",
        "\n",
        "# Dist 199 contains the distance of 200th nearest neighbour.\n",
        "    return dists[199]\n",
        "\n",
        "vectors.shape"
      ],
      "metadata": {
        "id": "J26aPfsKTMqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the 200th nearest neighbour distance of some point the dataset:\n",
        "twohundrethneigh = []\n",
        "for val in vectors[:1000]:\n",
        "    twohundrethneigh.append( compute200thnearestneighbour(val, vectors[:1000]) )\n",
        "twohundrethneigh.sort()"
      ],
      "metadata": {
        "id": "rYKbPXpZVmXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting for the Elbow Method :\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(14,4))\n",
        "plt.title(\"Elbow Method for Finding the right Eps hyperparameter\")\n",
        "plt.plot([x for x in range(len(twohundrethneigh))], twohundrethneigh)\n",
        "plt.xlabel(\"Number of points\")\n",
        "plt.ylabel(\"Distance of 200th Nearest Neighbour\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KaZUtODOWCV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model_dbs = DBSCAN(eps = 5, min_samples = minPts)\n",
        "model_dbs.fit(vectors)"
      ],
      "metadata": {
        "id": "Ro-RPRu9WCb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dbs = df\n",
        "df_dbs[\"DBS Cluster Label\"] = model_dbs.labels_\n",
        "df_dbs"
      ],
      "metadata": {
        "id": "28q0VHnWWLOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hierarchical clustering\n",
        "\n",
        "import scipy\n",
        "from scipy.cluster import hierarchy\n",
        "dendro=hierarchy.dendrogram(hierarchy.linkage(vectors,method='ward'))\n",
        "plt.axhline(y=20)"
      ],
      "metadata": {
        "id": "74rrIGo8WLTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  #took n=3 from dendrogram curve\n",
        "Agg=cluster.fit_predict(vectors)"
      ],
      "metadata": {
        "id": "NjQ_PIYTWLYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AVG-W2V Clus Label'] = cluster.labels_\n",
        "df.head()"
      ],
      "metadata": {
        "id": "g3fZpVHVWLeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hier_df = df # Give the labels and group to count the number of data in each clusters.\n",
        "hier_df[\"Hierarchial Cluster Labels\"] = cluster.labels_\n",
        "hier_df.groupby([\"Hierarchial Cluster Labels\"])[\"Reviews\"].count()"
      ],
      "metadata": {
        "id": "Ic2oo3WGWLjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6sI2iB6TWLps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word2vec\n",
        "\n",
        "\n",
        "#df = pd.read_csv('/content/Amazon_Unlocked_Mobile.csv')\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('/content/Amazon_Unlocked_Mobile.csv')\n",
        "\n",
        "# Check for NaN values and replace them with an empty string\n",
        "df['Reviews'] = df['Reviews'].fillna('')\n",
        "\n",
        "# Train Word2Vec model\n",
        "sentences = [review.split() for review in df['Reviews']]\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Create feature vectors for clustering\n",
        "features = []\n",
        "for words in sentences:\n",
        "    if words:\n",
        "        vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "        if vectors:\n",
        "            features.append(sum(vectors) / len(vectors))\n",
        "        else:\n",
        "            features.append([0]*100)  # or any other default value\n",
        "    else:\n",
        "        features.append([0]*100)  # or any other default value\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "# Apply K-means clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "df['Cluster'] = kmeans.fit_predict(scaled_features)\n"
      ],
      "metadata": {
        "id": "fYV8weAqWLv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ab20ef-2723-4d02-a699-bf39ef5d8ee2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "# pip install transformers\n",
        "# pip install scikit-learn\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/Amazon_Unlocked_Mobile.csv')\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "tokenized_text = df['text_column'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "# Use BERT to get embeddings\n",
        "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "\n",
        "# Get the embeddings\n",
        "embeddings = []\n",
        "for text in tokenized_text:\n",
        "    input_ids = torch.tensor([text])\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "        hidden_states = outputs.hidden_states\n",
        "    # Use the embeddings from the last layer\n",
        "    embeddings.append(hidden_states[-1].mean(dim=1).squeeze().numpy())\n",
        "\n",
        "# Apply K-means clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "df['cluster'] = kmeans.fit_predict(embeddings)\n",
        "\n",
        "# Print the clusters\n",
        "print(df[['text_column', 'cluster']])\n"
      ],
      "metadata": {
        "id": "8Ch745YSVmcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xqE3ng5eFbg"
      },
      "source": [
        "In one paragraph, please compare the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZ_1mSG7eFbg"
      },
      "outputs": [],
      "source": [
        "#You can write you answer here. (No code needed)\n",
        "\n",
        "Unsupervised machine learning algorithms used for clustering include K-means, DBSCAN, and Hierarchical clustering. K-means divides data into k clusters according to similarity\n",
        "however, it needs the number of clusters to be defined and may have trouble with non-spherical clusters. DBSCAN is responsive to parameter adjustments and detects clusters based on density, adjusting effectively to different forms and sizes. Although it can be computationally demanding, hierarchical clustering creates a tree-like structure of clusters that provides insights into data linkages. Word2Vec is a word embedding approach that is frequently used in natural language processing applications. It represents words as vectors, encapsulating semantic links between them. For tasks like question answering and sentiment analysis, BERT, a transformer-based model, performs exceptionally well in contextual language understanding.\n",
        "It captures complex relationships inside phrases. Every technique serves different\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}